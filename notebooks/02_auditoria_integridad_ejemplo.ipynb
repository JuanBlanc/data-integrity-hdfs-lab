{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d1169d7",
   "metadata": {},
   "source": [
    "# Auditoría de Integridad y Métricas — DataSecure Lab\n",
    "\n",
    "Este notebook lee las auditorías generadas por los scripts del pipeline (`30_fsck_audit.sh`) y construye tablas resumen con métricas de integridad y recomendaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f83a3d2",
   "metadata": {},
   "source": [
    "## 1) Configuración de rutas\n",
    "\n",
    "En el entorno del aula, el NameNode monta un volumen (por ejemplo `./notebooks` → `/media/notebooks`).\n",
    "La idea es que el script `30_fsck_audit.sh` deje copias de auditoría en una ruta que Jupyter pueda leer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9aa5497",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Ruta al directorio de auditorías (montado desde docker-compose)\n",
    "AUDIT_DIR = Path('/media/notebooks/audit/fsck')\n",
    "INVENTORY_DIR = Path('/media/notebooks/audit/inventory')\n",
    "METRICS_DIR = Path('/media/notebooks/audit/metrics')\n",
    "\n",
    "print('AUDIT_DIR exists:', AUDIT_DIR.exists())\n",
    "print('INVENTORY_DIR exists:', INVENTORY_DIR.exists())\n",
    "print('METRICS_DIR exists:', METRICS_DIR.exists())\n",
    "\n",
    "if AUDIT_DIR.exists():\n",
    "    print('Contenido de AUDIT_DIR:', sorted(AUDIT_DIR.glob('*'))[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9b86c0",
   "metadata": {},
   "source": [
    "## 2) Parseo básico de fsck\n",
    "\n",
    "Contabilizamos palabras clave típicas:\n",
    "- `CORRUPT`\n",
    "- `MISSING`\n",
    "- `Under replicated`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a88231",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_fsck_text(text: str) -> dict:\n",
    "    \"\"\"Extrae métricas clave de una salida de hdfs fsck.\"\"\"\n",
    "    metrics = {\n",
    "        'CORRUPT': len(re.findall(r'\\bCORRUPT\\b', text, flags=re.IGNORECASE)),\n",
    "        'MISSING': len(re.findall(r'\\bMISSING\\b', text, flags=re.IGNORECASE)),\n",
    "        'UNDER_REPLICATED': len(re.findall(r'Under replicated', text, flags=re.IGNORECASE)),\n",
    "    }\n",
    "    \n",
    "    # Extraer total size\n",
    "    size_match = re.search(r'Total size:\\s+(\\d+)', text)\n",
    "    metrics['total_size_bytes'] = int(size_match.group(1)) if size_match else 0\n",
    "    \n",
    "    # Extraer total files\n",
    "    files_match = re.search(r'Total files:\\s+(\\d+)', text)\n",
    "    metrics['total_files'] = int(files_match.group(1)) if files_match else 0\n",
    "    \n",
    "    # Extraer total blocks\n",
    "    blocks_match = re.search(r'Total blocks[^:]*:\\s+(\\d+)', text)\n",
    "    metrics['total_blocks'] = int(blocks_match.group(1)) if blocks_match else 0\n",
    "    \n",
    "    # Estado general\n",
    "    if 'HEALTHY' in text:\n",
    "        metrics['status'] = 'HEALTHY'\n",
    "    elif 'CORRUPT' in text.upper():\n",
    "        metrics['status'] = 'CORRUPT'\n",
    "    else:\n",
    "        metrics['status'] = 'UNKNOWN'\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Recopilar auditorías de todos los días disponibles\n",
    "rows = []\n",
    "for dt_dir in sorted(AUDIT_DIR.glob('*')):\n",
    "    if not dt_dir.is_dir():\n",
    "        continue\n",
    "    # Buscar todos los ficheros fsck en el directorio\n",
    "    for fsck_file in sorted(dt_dir.glob('fsck_*.txt')):\n",
    "        text = fsck_file.read_text(encoding='utf-8', errors='ignore')\n",
    "        m = parse_fsck_text(text)\n",
    "        m['date'] = dt_dir.name\n",
    "        m['audit_type'] = fsck_file.stem  # e.g. fsck_data, fsck_pre_incident, etc.\n",
    "        rows.append(m)\n",
    "\n",
    "df_audit = pd.DataFrame(rows) if rows else pd.DataFrame(\n",
    "    columns=['date', 'audit_type', 'CORRUPT', 'MISSING', 'UNDER_REPLICATED', \n",
    "             'total_size_bytes', 'total_files', 'total_blocks', 'status']\n",
    ")\n",
    "\n",
    "print(f\"Total de auditorías encontradas: {len(df_audit)}\")\n",
    "df_audit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e258bf62",
   "metadata": {},
   "source": [
    "## 3) Análisis del incidente\n",
    "\n",
    "Comparación antes/después del incidente (caída de DataNode)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc991e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar auditorías pre y post incidente\n",
    "incident_types = ['fsck_pre_incident', 'fsck_post_incident', 'fsck_recovery', 'fsck_final']\n",
    "df_incident = df_audit[df_audit['audit_type'].isin(incident_types)].copy()\n",
    "\n",
    "if not df_incident.empty:\n",
    "    print(\"=== Evolución del incidente ===\")\n",
    "    print(df_incident[['audit_type', 'CORRUPT', 'MISSING', 'UNDER_REPLICATED', 'status']].to_string(index=False))\n",
    "else:\n",
    "    print(\"No se encontraron auditorías de incidente. Ejecuta 70_incident_simulation.sh y 80_recovery_restore.sh primero.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ivasjev3rv",
   "metadata": {},
   "source": [
    "## 4) Tabla de métricas de rendimiento\n",
    "\n",
    "Completar con los tiempos obtenidos durante la ejecución del pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "h20n5epnrrp",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabla de métricas — completar con valores reales tras la ejecución\n",
    "metrics_data = {\n",
    "    'Operacion': [\n",
    "        'Generacion de datos',\n",
    "        'Ingesta logs a HDFS',\n",
    "        'Ingesta IoT a HDFS',\n",
    "        'Copia backup logs',\n",
    "        'Copia backup IoT',\n",
    "        'Auditoria fsck',\n",
    "        'Comparacion inventario',\n",
    "    ],\n",
    "    'Tiempo_seg': [\n",
    "        0,  # Completar con tiempo real\n",
    "        0,  # Completar con tiempo real\n",
    "        0,  # Completar con tiempo real\n",
    "        0,  # Completar con tiempo real\n",
    "        0,  # Completar con tiempo real\n",
    "        0,  # Completar con tiempo real\n",
    "        0,  # Completar con tiempo real\n",
    "    ],\n",
    "    'Tamano_MB': [\n",
    "        0,  # Completar\n",
    "        0,  # Completar\n",
    "        0,  # Completar\n",
    "        0,  # Completar\n",
    "        0,  # Completar\n",
    "        0,  # N/A\n",
    "        0,  # N/A\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_metrics = pd.DataFrame(metrics_data)\n",
    "print(\"=== Métricas de rendimiento ===\")\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oslysbpup5k",
   "metadata": {},
   "source": [
    "## 5) Impacto de replicación\n",
    "\n",
    "Comparación del coste de almacenamiento según factor de replicación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dgcvscsye2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impacto de replicación — leer datos reales del script 60_replication_metrics.sh\n",
    "# Si no hay datos reales, se muestran valores placeholder\n",
    "\n",
    "df_replication = None\n",
    "\n",
    "# Intentar leer CSV generado por el script\n",
    "for dt_dir in sorted(METRICS_DIR.glob('*')) if METRICS_DIR.exists() else []:\n",
    "    rep_csv = dt_dir / 'replication_metrics.csv'\n",
    "    if rep_csv.exists():\n",
    "        df_replication = pd.read_csv(rep_csv)\n",
    "        df_replication['tolerancia_fallos'] = df_replication['factor'].map({\n",
    "            1: 'Sin tolerancia',\n",
    "            2: 'Tolera 1 fallo',\n",
    "            3: 'Tolera 1 fallo + re-replicación segura'\n",
    "        })\n",
    "        print(f\"Datos de replicación leídos desde: {rep_csv}\")\n",
    "        break\n",
    "\n",
    "# Si no hay datos reales, crear tabla placeholder\n",
    "if df_replication is None:\n",
    "    replication_data = {\n",
    "        'factor': [1, 2, 3],\n",
    "        'logical_size_bytes': [0, 0, 0],\n",
    "        'physical_size_bytes': [0, 0, 0],\n",
    "        'physical_size_mb': [0, 0, 0],\n",
    "        'time_setrep_sec': [0, 0, 0],\n",
    "        'tolerancia_fallos': [\n",
    "            'Sin tolerancia',\n",
    "            'Tolera 1 fallo',\n",
    "            'Tolera 1 fallo + re-replicación segura'\n",
    "        ]\n",
    "    }\n",
    "    df_replication = pd.DataFrame(replication_data)\n",
    "    print(\"Sin datos reales. Ejecuta 60_replication_metrics.sh primero.\")\n",
    "\n",
    "print(\"\\n=== Impacto de replicación ===\")\n",
    "df_replication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qvinm5m9dcj",
   "metadata": {},
   "source": [
    "## 6) Conclusiones y recomendaciones\n",
    "\n",
    "Basándonos en las métricas recogidas:\n",
    "\n",
    "**Factor de replicación recomendado: 3**\n",
    "- Con 3 DataNodes y replicación 3, cada bloque tiene copia en todos los nodos.\n",
    "- Ante la caída de un nodo, HDFS re-replica automáticamente desde las 2 réplicas restantes.\n",
    "- El coste es 3x en disco, pero el clúster educativo tiene capacidad suficiente.\n",
    "\n",
    "**Frecuencia de auditoría recomendada: diaria**\n",
    "- La auditoría con `hdfs fsck` es una operación de solo lectura (metadata) y no impacta el rendimiento.\n",
    "- Una auditoría diaria permite detectar bloques UNDER_REPLICATED o CORRUPT antes de que se acumulen.\n",
    "- En producción con volúmenes mayores, una frecuencia semanal podría ser más adecuada, complementada con alertas automáticas del NameNode.\n",
    "\n",
    "**Estrategia de prevención:**\n",
    "- Mantener siempre replicación >= 2 para tolerancia a fallos.\n",
    "- Backup periódico a `/backup` con validación por inventario.\n",
    "- Monitorizar el NameNode UI para detectar Dead Nodes o Under-replicated blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bvx43lafgcm",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar todas las tablas a CSV\n",
    "out_dir = Path('.')\n",
    "\n",
    "df_audit.to_csv(out_dir / 'audit_summary.csv', index=False)\n",
    "print(f\"Exportado: {out_dir / 'audit_summary.csv'}\")\n",
    "\n",
    "df_metrics.to_csv(out_dir / 'metrics_summary.csv', index=False)\n",
    "print(f\"Exportado: {out_dir / 'metrics_summary.csv'}\")\n",
    "\n",
    "df_replication.to_csv(out_dir / 'replication_comparison.csv', index=False)\n",
    "print(f\"Exportado: {out_dir / 'replication_comparison.csv'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
