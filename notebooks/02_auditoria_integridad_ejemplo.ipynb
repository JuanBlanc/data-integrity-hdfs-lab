{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Auditoría de Integridad y Métricas — DataSecure Lab\n\nEste notebook lee las auditorías generadas por los scripts del pipeline (`30_fsck_audit.sh`) y construye tablas resumen con métricas de integridad y recomendaciones."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Configuración de rutas\n\n",
    "En el entorno del aula, el NameNode monta un volumen (por ejemplo `./notebooks` → `/media/notebooks`).\n",
    "La idea es que el script `30_fsck_audit.sh` deje copias de auditoría en una ruta que Jupyter pueda leer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from pathlib import Path\nimport pandas as pd\nimport re\n\n# Ruta al directorio de auditorías (montado desde docker-compose)\nAUDIT_DIR = Path('/media/notebooks/audit/fsck')\nINVENTORY_DIR = Path('/media/notebooks/audit/inventory')\nMETRICS_DIR = Path('/media/notebooks/audit/metrics')\n\nprint('AUDIT_DIR exists:', AUDIT_DIR.exists())\nprint('INVENTORY_DIR exists:', INVENTORY_DIR.exists())\nprint('METRICS_DIR exists:', METRICS_DIR.exists())\n\nif AUDIT_DIR.exists():\n    print('Contenido de AUDIT_DIR:', sorted(AUDIT_DIR.glob('*'))[:10])"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Parseo básico de fsck\n\n",
    "Contabilizamos palabras clave típicas:\n",
    "- `CORRUPT`\n",
    "- `MISSING`\n",
    "- `Under replicated`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def parse_fsck_text(text: str) -> dict:\n    \"\"\"Extrae métricas clave de una salida de hdfs fsck.\"\"\"\n    metrics = {\n        'CORRUPT': len(re.findall(r'\\bCORRUPT\\b', text, flags=re.IGNORECASE)),\n        'MISSING': len(re.findall(r'\\bMISSING\\b', text, flags=re.IGNORECASE)),\n        'UNDER_REPLICATED': len(re.findall(r'Under replicated', text, flags=re.IGNORECASE)),\n    }\n    \n    # Extraer total size\n    size_match = re.search(r'Total size:\\s+(\\d+)', text)\n    metrics['total_size_bytes'] = int(size_match.group(1)) if size_match else 0\n    \n    # Extraer total files\n    files_match = re.search(r'Total files:\\s+(\\d+)', text)\n    metrics['total_files'] = int(files_match.group(1)) if files_match else 0\n    \n    # Extraer total blocks\n    blocks_match = re.search(r'Total blocks[^:]*:\\s+(\\d+)', text)\n    metrics['total_blocks'] = int(blocks_match.group(1)) if blocks_match else 0\n    \n    # Estado general\n    if 'HEALTHY' in text:\n        metrics['status'] = 'HEALTHY'\n    elif 'CORRUPT' in text.upper():\n        metrics['status'] = 'CORRUPT'\n    else:\n        metrics['status'] = 'UNKNOWN'\n    \n    return metrics\n\n# Recopilar auditorías de todos los días disponibles\nrows = []\nfor dt_dir in sorted(AUDIT_DIR.glob('*')):\n    if not dt_dir.is_dir():\n        continue\n    # Buscar todos los ficheros fsck en el directorio\n    for fsck_file in sorted(dt_dir.glob('fsck_*.txt')):\n        text = fsck_file.read_text(encoding='utf-8', errors='ignore')\n        m = parse_fsck_text(text)\n        m['date'] = dt_dir.name\n        m['audit_type'] = fsck_file.stem  # e.g. fsck_data, fsck_pre_incident, etc.\n        rows.append(m)\n\ndf_audit = pd.DataFrame(rows) if rows else pd.DataFrame(\n    columns=['date', 'audit_type', 'CORRUPT', 'MISSING', 'UNDER_REPLICATED', \n             'total_size_bytes', 'total_files', 'total_blocks', 'status']\n)\n\nprint(f\"Total de auditorías encontradas: {len(df_audit)}\")\ndf_audit"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3) Análisis del incidente\n\nComparación antes/después del incidente (caída de DataNode)."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Filtrar auditorías pre y post incidente\nincident_types = ['fsck_pre_incident', 'fsck_post_incident', 'fsck_recovery', 'fsck_final']\ndf_incident = df_audit[df_audit['audit_type'].isin(incident_types)].copy()\n\nif not df_incident.empty:\n    print(\"=== Evolución del incidente ===\")\n    print(df_incident[['audit_type', 'CORRUPT', 'MISSING', 'UNDER_REPLICATED', 'status']].to_string(index=False))\nelse:\n    print(\"No se encontraron auditorías de incidente. Ejecuta 70_incident_simulation.sh y 80_recovery_restore.sh primero.\")"
  },
  {
   "cell_type": "markdown",
   "id": "1ivasjev3rv",
   "source": "## 4) Tabla de métricas de rendimiento\n\nCompletar con los tiempos obtenidos durante la ejecución del pipeline.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "h20n5epnrrp",
   "source": "# Tabla de métricas — completar con valores reales tras la ejecución\nmetrics_data = {\n    'Operacion': [\n        'Generacion de datos',\n        'Ingesta logs a HDFS',\n        'Ingesta IoT a HDFS',\n        'Copia backup logs',\n        'Copia backup IoT',\n        'Auditoria fsck',\n        'Comparacion inventario',\n    ],\n    'Tiempo_seg': [\n        0,  # Completar con tiempo real\n        0,  # Completar con tiempo real\n        0,  # Completar con tiempo real\n        0,  # Completar con tiempo real\n        0,  # Completar con tiempo real\n        0,  # Completar con tiempo real\n        0,  # Completar con tiempo real\n    ],\n    'Tamano_MB': [\n        0,  # Completar\n        0,  # Completar\n        0,  # Completar\n        0,  # Completar\n        0,  # Completar\n        0,  # N/A\n        0,  # N/A\n    ]\n}\n\ndf_metrics = pd.DataFrame(metrics_data)\nprint(\"=== Métricas de rendimiento ===\")\ndf_metrics",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "oslysbpup5k",
   "source": "## 5) Impacto de replicación\n\nComparación del coste de almacenamiento según factor de replicación.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "dgcvscsye2",
   "source": "# Impacto de replicación — leer datos reales del script 60_replication_metrics.sh\n# Si no hay datos reales, se muestran valores placeholder\n\ndf_replication = None\n\n# Intentar leer CSV generado por el script\nfor dt_dir in sorted(METRICS_DIR.glob('*')) if METRICS_DIR.exists() else []:\n    rep_csv = dt_dir / 'replication_metrics.csv'\n    if rep_csv.exists():\n        df_replication = pd.read_csv(rep_csv)\n        df_replication['tolerancia_fallos'] = df_replication['factor'].map({\n            1: 'Sin tolerancia',\n            2: 'Tolera 1 fallo',\n            3: 'Tolera 1 fallo + re-replicación segura'\n        })\n        print(f\"Datos de replicación leídos desde: {rep_csv}\")\n        break\n\n# Si no hay datos reales, crear tabla placeholder\nif df_replication is None:\n    replication_data = {\n        'factor': [1, 2, 3],\n        'logical_size_bytes': [0, 0, 0],\n        'physical_size_bytes': [0, 0, 0],\n        'physical_size_mb': [0, 0, 0],\n        'time_setrep_sec': [0, 0, 0],\n        'tolerancia_fallos': [\n            'Sin tolerancia',\n            'Tolera 1 fallo',\n            'Tolera 1 fallo + re-replicación segura'\n        ]\n    }\n    df_replication = pd.DataFrame(replication_data)\n    print(\"Sin datos reales. Ejecuta 60_replication_metrics.sh primero.\")\n\nprint(\"\\n=== Impacto de replicación ===\")\ndf_replication",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "qvinm5m9dcj",
   "source": "## 6) Conclusiones y recomendaciones\n\nBasándonos en las métricas recogidas:\n\n**Factor de replicación recomendado: 3**\n- Con 3 DataNodes y replicación 3, cada bloque tiene copia en todos los nodos.\n- Ante la caída de un nodo, HDFS re-replica automáticamente desde las 2 réplicas restantes.\n- El coste es 3x en disco, pero el clúster educativo tiene capacidad suficiente.\n\n**Frecuencia de auditoría recomendada: diaria**\n- La auditoría con `hdfs fsck` es una operación de solo lectura (metadata) y no impacta el rendimiento.\n- Una auditoría diaria permite detectar bloques UNDER_REPLICATED o CORRUPT antes de que se acumulen.\n- En producción con volúmenes mayores, una frecuencia semanal podría ser más adecuada, complementada con alertas automáticas del NameNode.\n\n**Estrategia de prevención:**\n- Mantener siempre replicación >= 2 para tolerancia a fallos.\n- Backup periódico a `/backup` con validación por inventario.\n- Monitorizar el NameNode UI para detectar Dead Nodes o Under-replicated blocks.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "bvx43lafgcm",
   "source": "# Exportar todas las tablas a CSV\nout_dir = Path('.')\n\ndf_audit.to_csv(out_dir / 'audit_summary.csv', index=False)\nprint(f\"Exportado: {out_dir / 'audit_summary.csv'}\")\n\ndf_metrics.to_csv(out_dir / 'metrics_summary.csv', index=False)\nprint(f\"Exportado: {out_dir / 'metrics_summary.csv'}\")\n\ndf_replication.to_csv(out_dir / 'replication_comparison.csv', index=False)\nprint(f\"Exportado: {out_dir / 'replication_comparison.csv'}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}